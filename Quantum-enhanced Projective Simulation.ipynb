{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the quadratic speed-up of Quantum-enhanced Reflective Projective Simulation\n",
    "\n",
    "SofiÃ¨ne Jerbi (sofiene.jerbi@telecom-paristech.fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from qutip import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from numpy import pi, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function we define to be used all along the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure(state, size=1):\n",
    "    \"\"\"For a given state returns a measurement (or \\'size\\' measurements, if specified) of the state in\n",
    "    the computational basis along with its wavefunction (probabilities of each outcome)\"\"\"\n",
    "    n = state.shape[0]\n",
    "    probs = np.abs(state.dag().full())**2\n",
    "    probs = probs.reshape(n)\n",
    "    if size>1:\n",
    "        draw = np.random.choice(n,p=probs,size=size)\n",
    "    else:\n",
    "        draw = np.random.choice(n,p=probs)\n",
    "    return(draw,list(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [0.49999999999999989, 0.49999999999999989])\n"
     ]
    }
   ],
   "source": [
    "bell = (basis(2,0)+basis(2,1))/math.sqrt(2)\n",
    "print(measure(bell))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rank-One Reflecting PS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the following part if to show how quantum-enhancement allows to keep one the good features of PS, its reactivity to environment changes, even when adding an additional structure (Reflecting PS and flags) that increases learning efficiency but induces longer deliberation times, especially in the case of changes in the environment.\n",
    "Let us set the context and explain this further:\n",
    "\n",
    "We consider the case where the transition matrix $P$ associated to the MCs of the percept-specific sub-networks of the \"two-layered\" RPS agent's ECM have rank one. As specified in the appendix of https://arxiv.org/pdf/1407.2830.pdf this leads to many simplifications:\n",
    "- The columns of $P$ are all identical, equal to the stationnary distribution, so all unitaries $U_i$ are the same equal to $U$ (given by formula A.1)\n",
    "- $P$ has only one eigenvalue (+1) and one eigenvector (the stationnary distribution) which leads to a spectral gap $\\delta = 1$\n",
    "- The Markov chain mixes in one step\n",
    "- The Szegedy Walk operator becomes $W(P) = UD_0U^\\dagger$ and is hermitian, then exact reflection over the stationary distribution can be achieved by applying $W(P)$ once on only one register\n",
    "\n",
    "We deal with the simple \"Invasion game\" with a set of three percepts and three actions. We focus on the sub-network associated to one percept but our results apply also for the other percepts by the rank-one induced symmetry. We define the stationnary action probabilities $\\pi = (\\pi_1,\\pi_2,\\pi_3)$ and add the *flags* (or *emoticons*) structure to the network, increasing the learning efficiency of the agent but inducing a longer deliberation time to output an action because of the multiple reflections the RPS agent has to go through to output a *flagged* action. This number of reflections is determined by $epsilon = \\sum_{i\\in F} \\pi_i$ the relative probability of flagged actions within the stationnary distribution, scaling as $\\tilde{O}(1/\\sqrt{\\epsilon})$ for the quantum RPS agent and as $\\tilde{O}(1/\\epsilon)$ for the classical RPS agent.\n",
    "\n",
    "To exhibit the better reactivity of quantum RS to environment changes, which happens to be the case when epsilon is the smallest (so when the difference in the dependencies on $\\epsilon$ is the largest), we deal with the change in strategy of the adversary (i.e. the environment) by permuting the meaning of percepts. Suppose the adversary pursues a consistent strategy (i.e. gives the same hints, or percepts, to the agent before each of its moves) for a long period of time. The agent would have learned well, which means that for a given percept he would associated with high probability an action (i.e. $\\pi_3 >> \\pi_1 +\\pi_2$ for example) and only the action clip associated to $\\pi_3$ would be flagged. Then the adversary changes his strategy, which means that now the flagged actions are reset, and become (after one unsuccessful trial on the action associated to $\\pi_3$) the actions clips associated to $\\pi_1$ and $\\pi_2$, with cumulated probability $\\epsilon = \\pi_1 +\\pi_2 << 1$.\n",
    "\n",
    "Let's now dig into the simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "p1 = epsilon/3\n",
    "p2 = epsilon-p1\n",
    "p3 = 1-epsilon\n",
    "distrib = [p1,p2,p3/2,p3/2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define $U$ with the formula A.1 given in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ux = (0.5*math.pi*0.5j*(tensor(sigmax(),qeye(2))+tensor(qeye(2),sigmax()))).expm()\n",
    "Uz2 = tensor(qeye(2),rz(2*math.acos(sqrt(p1/epsilon))))\n",
    "Uz1 = tensor(rz(2*math.acos(sqrt(epsilon))),qeye(2))\n",
    "Uxb = (-0.5*math.pi*0.5j*(tensor(sigmax(),qeye(2))+tensor(qeye(2),sigmax()))).expm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = False\\begin{equation*}\\left(\\begin{array}{*{11}c}0.183 & -0.258 & -0.548 & 0.775\\\\0.258 & 0.183 & -0.775 & -0.548\\\\0.548 & -0.775 & 0.183 & -0.258\\\\0.775 & 0.548 & 0.258 & 0.183\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = False\n",
       "Qobj data =\n",
       "[[ 0.18257419 -0.25819889 -0.54772256  0.77459667]\n",
       " [ 0.25819889  0.18257419 -0.77459667 -0.54772256]\n",
       " [ 0.54772256 -0.77459667  0.18257419 -0.25819889]\n",
       " [ 0.77459667  0.54772256  0.25819889  0.18257419]]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = Ux*Uz2*Uz1*Uxb\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = True\\begin{equation*}\\left(\\begin{array}{*{11}c}1.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 1.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 1.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 1.000\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = True\n",
       "Qobj data =\n",
       "[[ 1.  0.  0.  0.]\n",
       " [ 0.  1.  0.  0.]\n",
       " [ 0.  0.  1.  0.]\n",
       " [ 0.  0.  0.  1.]]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.dag()*U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.033333333333333319, 0.066666666666666735, 0.29999999999999993, 0.60000000000000009]\n"
     ]
    }
   ],
   "source": [
    "print(measure(U*tensor(basis(2,0),basis(2,0)))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$U$ applied to the state |$0$> indeed gives the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define the reflection over the flagged actions $Uz1b$ and the Szegedy walk operator $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = False\\begin{equation*}\\left(\\begin{array}{*{11}c}-1.0j & 0.0 & 0.0 & 0.0\\\\0.0 & -1.0j & 0.0 & 0.0\\\\0.0 & 0.0 & 1.0j & 0.0\\\\0.0 & 0.0 & 0.0 & 1.0j\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [2, 2]], shape = (4, 4), type = oper, isherm = False\n",
       "Qobj data =\n",
       "[[ 0.-1.j  0.+0.j  0.+0.j  0.+0.j]\n",
       " [ 0.+0.j  0.-1.j  0.+0.j  0.+0.j]\n",
       " [ 0.+0.j  0.+0.j  0.+1.j  0.+0.j]\n",
       " [ 0.+0.j  0.+0.j  0.+0.j  0.+1.j]]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uz1b = tensor(rz(pi),qeye(2))\n",
    "Uz1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null = tensor(basis(2,0),basis(2,0))\n",
    "D0 = 2*null*null.dag()-tensor(qeye(2),qeye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = U*D0*U.dag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulation_rankone(step_e, max_e, nb_agnts, clssc=False):\n",
    "    \"\"\"\n",
    "    simulation_rankone simulates for nb_agnts agents the quantum walk (and also the classical walk if clssc is set)\n",
    "    on the subnetwork associated to the first percept for epsilon <= max_e with step step_e. It stores the number of\n",
    "    calls of U before a flagged action is hit for each simulation in NUss for the quantum agents and in NUss_clssc for\n",
    "    the classical agents. It also stores the number of times the first percept or the second percept are hit in N1s\n",
    "    and N2s respectively.\n",
    "    \"\"\"\n",
    "    epsilons = np.arange(max_e, 0.0-step_e, -step_e)[:-1]\n",
    "    N1s = []\n",
    "    N2s = []\n",
    "    NUss = []\n",
    "    NUss_clssc = []\n",
    "    flagged = 1\n",
    "    old_perc = 0\n",
    "    for epsilon in epsilons:\n",
    "        p1 = epsilon/3\n",
    "        Uz2 = tensor(qeye(2),rz(2*math.acos(sqrt(p1/epsilon))))\n",
    "        Uz1 = tensor(rz(2*math.acos(sqrt(epsilon))),qeye(2))\n",
    "        U = Ux*Uz2*Uz1*Uxb\n",
    "        W = U*D0*U.dag()\n",
    "        me = math.ceil(1/sqrt(epsilon))\n",
    "        N1 = 0\n",
    "        N2 = 0\n",
    "        NUs = []\n",
    "        NUs_clssc = []\n",
    "        for i in range(nb_agnts):\n",
    "            NU = 0\n",
    "            fnd = False\n",
    "            while not fnd:\n",
    "                R1 = tensor(basis(2,0),basis(2,0))\n",
    "                m = random.randint(0,me)\n",
    "                NU+=3*m\n",
    "                R1 = U*R1\n",
    "                for j in range(m):\n",
    "                    R1 = Uz1b*R1\n",
    "                    R1 = W*R1\n",
    "                res = measure(R1)[0]\n",
    "                if res<=flagged:\n",
    "                    fnd = True\n",
    "                    if res==0:\n",
    "                        N1+=1\n",
    "                    else:\n",
    "                        N2+=1\n",
    "            NUs+=[NU]\n",
    "            if clssc:\n",
    "                NU = 0\n",
    "                fnd = False\n",
    "                while not fnd:\n",
    "                    NU+=1\n",
    "                    R1 = tensor(basis(2,0),basis(2,0))\n",
    "                    R1 = U*R1\n",
    "                    res = measure(R1)[0]\n",
    "                    if res<=flagged:\n",
    "                        fnd = True\n",
    "                NUs_clssc+=[NU]\n",
    "        NUss+=[NUs]\n",
    "        NUss_clssc+=[NUs_clssc]\n",
    "        N1s+=[N1]\n",
    "        N2s+=[N2]\n",
    "        perc = 100*(1-epsilon/epsilons[0])\n",
    "        if perc >= old_perc+10:\n",
    "            old_perc = 10*int(perc/10)\n",
    "            print(int(perc),\"%\")\n",
    "    print(\"done\")\n",
    "    if clssc:\n",
    "        return(epsilons, NUss, NUss_clssc, N1s, N2s)\n",
    "    else:\n",
    "        return(epsilons, NUss, N1s, N2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 %\n",
      "20 %\n",
      "30 %\n",
      "40 %\n",
      "50 %\n",
      "60 %\n",
      "70 %\n",
      "80 %\n",
      "90 %\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "epsilons, NUss = simulation_rankone(0.002, 0.10, 1000)[:2]\n",
    "NUss_mean = []\n",
    "for NUs in NUss:\n",
    "    NUss_mean+=[np.mean(NUs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwigYREQkjIJBRETCKBhERCTM/weVrPrbWl8b2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8cd7990630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, NUss_mean)\n",
    "\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('$N_U$')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 %\n",
      "20 %\n",
      "30 %\n",
      "40 %\n",
      "50 %\n",
      "60 %\n",
      "70 %\n",
      "80 %\n",
      "90 %\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "epsilonsb, NUssb, NUssb_classc = simulation_rankone(0.0005, 0.05, 1000, True)[:3]\n",
    "NUssb_mean = []\n",
    "for NUs in NUssb:\n",
    "    NUssb_mean+=[np.mean(NUs)]\n",
    "NUssb_classc_mean = []\n",
    "for NUs in NUssb_classc:\n",
    "    NUssb_classc_mean+=[np.mean(NUs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8cd7990e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilonsb, NUssb_mean)\n",
    "plt.plot(epsilonsb, NUssb_classc_mean)\n",
    "\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('$N_U$')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly get the quadratic seperation between the classical agents and the quantum agents as expected, proving by simulation the quantum-enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rank-two Reflecting PS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We showed in the previous section how quantum-enhancement of the RPS model allowed to keep the good reactivity of the agent to environment changes. Let us now show another good feature of the PS the quantum-enhancement preserves, the nice interplay between planning and real-time action selection.\n",
    "\n",
    "Indeed, in a more general case than the rank-one RPS, the ergodic MCs of the percept-specific subnetworks of the ECM don't completely mix in one step. This is because the mixing time of the MC (the number of applications of the transition matrix $P$ on an initial distribution to get a *good* approximation of the stationary distribtion) is inversely dependent of the spectral gap $\\delta = 1 - |\\lambda|$ (where $\\lambda$ is the largest eigenvalue of $P$ in absolute value after 1). But this mixing time is precisely the planning in the future that the agent performs as the more the MC is mixed, the better the stationary distribution is approximated and the more accurate is the planning of the agent. The mixing time or the number of application of $P$ (or $W(P)$ for the quantum agent) is determined by the spectral gap $\\delta$ scaling as $\\tilde{O}(1/\\sqrt{\\delta})$ for the quantum RPS agent and as $\\tilde{O}(1/\\delta)$ for the classical RPS agent.\n",
    "\n",
    "To show these dependencies, we consider a transition matrix $P$ with eigenvalues 1 and $\\lambda$, with $\\lambda$ set arbitrarily through a transformation of the rank-on transition matrix we had above:\n",
    "\\begin{split}\\begin{pmatrix}\n",
    "p_1+\\lambda & p_1 & p_1 & p_1\\\\\n",
    "p_2-\\lambda & p_2 & p_2 & p_2\\\\\n",
    "p_3 & p_3 & p_3 & p_3\\\\\n",
    "p_4 & p_4 & p_4 & p_4\n",
    "\\end{pmatrix}\\end{split}\n",
    "where $(p_1, p_2, p_3, p_4)$ refers to the stationary distribution in the previous case.\n",
    "\n",
    "Then the simplifications made in the first part disappear, we need to define different unitaries $U_1$ and $U_{\\{2,3,4\\}}$ for the first and {second, third and fourth} percepts respectively and apply the general Szegedy quantum walk operator and Phase Estimation algorithm. The stationary distribution becomes $(\\frac{p_1}{1-\\lambda}, p_2-p_1\\times \\frac{\\lambda}{1-\\lambda}, p_3, p_4)$.<br/>\n",
    "The constraints we have on $\\lambda$ (supposing it is positive) are:\n",
    "\\begin{split}\\begin{cases}\n",
    "\\frac{p_1}{1-\\lambda} \\leq 1 \\\\\n",
    "p_2-p_1\\times \\frac{\\lambda}{1-\\lambda} \\geq 0 \\\\\n",
    "p_1+\\lambda \\leq 1 \\\\\n",
    "p_2-\\lambda \\geq 0\n",
    "\\end{cases}\\end{split}\n",
    "\n",
    "Which sum up to $\\lambda \\in [0, min(1-p_1, p_2, \\frac{p_2}{p_1+p_2})]$. That can be further simplified if we take $p_1 < p_2$ and $p_1+p_2 < 1$ to $\\lambda \\in [0, p_2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first check these previous results on the transition matrix for a given $\\lambda = 0.6$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "p1 = epsilon/3\n",
    "p2 = epsilon-p1\n",
    "p3 = 1-epsilon\n",
    "distrib = [p1,p2,p3/2,p3/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63333333  0.03333333  0.03333333  0.03333333]\n",
      " [-0.53333333  0.06666667  0.06666667  0.06666667]\n",
      " [ 0.45        0.45        0.45        0.45      ]\n",
      " [ 0.45        0.45        0.45        0.45      ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "Pb = np.array([distrib]*4).transpose()\n",
    "P = np.array([distrib]*4).transpose()\n",
    "lmbd = 0.6\n",
    "Pb[0][0] += lmbd\n",
    "Pb[1][0] -= lmbd\n",
    "print(Pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.,  1.,  0., -0.]), array([[-0.83386369, -0.05202269,  0.83386369,  0.03673612],\n",
      "       [ 0.05750784, -0.10404537, -0.05750784,  0.80351628],\n",
      "       [ 0.38817792, -0.70230627, -0.38817792, -0.4201262 ],\n",
      "       [ 0.38817792, -0.70230627, -0.38817792, -0.4201262 ]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1. ,  0.6,  0. ,  0. ]),\n",
       " array([[-0.12979353, -0.70710678,  0.        , -0.        ],\n",
       "        [-0.02595871,  0.70710678,  0.15624556, -0.81504104],\n",
       "        [-0.70088508,  0.        , -0.77216204,  0.44972331],\n",
       "        [-0.70088508,  0.        ,  0.61591648,  0.36531774]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(LA.eig(P))\n",
    "LA.eig(Pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the transition matrix for the previous case has eigenvalue 1 only, whereas the modified transition matrix has eigenvalues 1 and $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also check that the stationnary distribution for this new transition matrix is the one we gave above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.49499999999999994, 0.0025000000000000022, 0.0025000000000000022]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.5   ,  0.495 ,  0.0025,  0.0025])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2=0.99\n",
    "lmbd = 0.99\n",
    "p1=(1-p2)/2\n",
    "p3=p1\n",
    "distrib = [p1,p2,p3/2,p3/2]\n",
    "Pb = np.array([distrib]*4).transpose()\n",
    "Pb[0][0] += lmbd\n",
    "Pb[1][0] -= lmbd\n",
    "print([p1/(1-lmbd),p2-p1*lmbd/(1-lmbd),p3/2,p3/2])\n",
    "Pb.dot([p1/(1-lmbd),p2-p1*lmbd/(1-lmbd),p3/2,p3/2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to simulate the complete algorithm, which a lot more complex than in the previous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=1\n",
    "lmbd = 1 - 2**(-2*n)\n",
    "p2 = lmbd\n",
    "p1 = (1-p2)/2\n",
    "p3 = 1-p1-p2\n",
    "distrib = [p1,p2,p3/2,p3/2]\n",
    "\n",
    "R1 = tensor(basis(2,0),basis(2,0))\n",
    "R2 = tensor(basis(2,0),basis(2,0))\n",
    "R = tensor(R1,R2)\n",
    "\n",
    "Ut1 = tensor(ry(2*math.acos(sqrt(p1+p2))),qeye(2))\n",
    "Ut2 = controlled_gate(ry(2*math.acos(sqrt(p1/(p1+p2)))), control_value=0)\n",
    "Ut2b = controlled_gate(ry(2*math.acos(sqrt((p1+lmbd)/(p1+p2)))), control_value=0)\n",
    "Ut3 = controlled_gate(ry(pi/2))\n",
    "U1 = Ut3*Ut2b*Ut1\n",
    "U2 = Ut3*Ut2*Ut1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93541435  0.          0.25        0.25      ]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\\begin{equation*}\\left(\\begin{array}{*{11}c}0.935\\\\0.0\\\\0.250\\\\0.250\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\n",
       "Qobj data =\n",
       "[[ 0.93541435]\n",
       " [ 0.        ]\n",
       " [ 0.25      ]\n",
       " [ 0.25      ]]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sqrt([p1+lmbd,p2-lmbd,p3/2,p3/2]))\n",
    "U1*R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35355339  0.8660254   0.25        0.25      ]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\\begin{equation*}\\left(\\begin{array}{*{11}c}0.354\\\\0.866\\\\0.250\\\\0.250\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\n",
       "Qobj data =\n",
       "[[ 0.35355339]\n",
       " [ 0.8660254 ]\n",
       " [ 0.25      ]\n",
       " [ 0.25      ]]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sqrt(distrib))\n",
    "U2*R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U2dc00 = tensor(tensor(fock_dm(2, 0), fock_dm(2, 0)),U2.dag()-tensor(qeye(2),qeye(2)))+tensor(tensor(qeye(2),qeye(2)),tensor(qeye(2),qeye(2)))\n",
    "U1c00 = tensor(tensor(fock_dm(2, 0), fock_dm(2, 0)),U1-tensor(qeye(2),qeye(2)))+tensor(tensor(qeye(2),qeye(2)),tensor(qeye(2),qeye(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2, 2, 2], [2, 2, 2, 2]], shape = (16, 16), type = oper, isherm = False\\begin{equation*}\\left(\\begin{array}{*{11}c}0.354 & 0.866 & 0.250 & 0.250 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\-0.866 & 0.354 & -0.250 & 0.250 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\-0.134 & -0.327 & 0.661 & 0.661 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.327 & -0.134 & -0.661 & 0.661 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 1.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 1.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 1.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 1.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 1.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 1.0\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2, 2, 2], [2, 2, 2, 2]], shape = (16, 16), type = oper, isherm = False\n",
       "Qobj data =\n",
       "[[ 0.35355339  0.8660254   0.25        0.25        0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [-0.8660254   0.35355339 -0.25        0.25        0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [-0.13363062 -0.32732684  0.66143783  0.66143783  0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.32732684 -0.13363062 -0.66143783  0.66143783  0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          1.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          1.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          1.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   1.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          1.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          1.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          1.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          1.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          1.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          1.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   1.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          1.        ]]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U2dc00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2, 2, 2], [2, 2, 2, 2]], shape = (16, 16), type = oper, isherm = False\\begin{equation*}\\left(\\begin{array}{*{11}c}0.935 & 0.0 & -0.354 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.935 & 0.0 & -0.354 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.250 & -0.250 & 0.661 & -0.661 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.250 & 0.250 & 0.661 & 0.661 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 1.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 1.0 & 0.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 1.0 & 0.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 1.0 & 0.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 1.0 & 0.0\\\\0.0 & 0.0 & 0.0 & 0.0 & 0.0 & \\cdots & 0.0 & 0.0 & 0.0 & 0.0 & 1.0\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2, 2, 2], [2, 2, 2, 2]], shape = (16, 16), type = oper, isherm = False\n",
       "Qobj data =\n",
       "[[ 0.93541435  0.         -0.35355339  0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.93541435  0.         -0.35355339  0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.25       -0.25        0.66143783 -0.66143783  0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.25        0.25        0.66143783  0.66143783  0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          1.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          1.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          1.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   1.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          1.          0.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          1.          0.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          1.          0.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          1.          0.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          1.          0.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          1.\n",
       "   0.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   1.          0.        ]\n",
       " [ 0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          0.          0.          0.          0.          0.          0.\n",
       "   0.          1.        ]]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U1c00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Up = U1c00*U2dc00*tensor(tensor(qeye(2),qeye(2)),U2)\n",
    "Vp = swap(N=4, targets=[0, 2])*swap(N=4, targets=[1, 3])*Up*swap(N=4, targets=[0, 2])*swap(N=4, targets=[1, 3])\n",
    "null = tensor(basis(2,0),basis(2,0))\n",
    "D0 = 2*null*null.dag()-tensor(qeye(2),qeye(2))\n",
    "refA = Up*tensor(tensor(qeye(2),qeye(2)),D0)*Up.dag()\n",
    "refB = Vp*tensor(D0,tensor(qeye(2),qeye(2)))*Vp.dag()\n",
    "W = refB*refA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=n\n",
    "\n",
    "Aux = basis(2,0)\n",
    "for i in range(k):\n",
    "    Aux = tensor(basis(2,0),Aux)\n",
    "nullaux = Aux\n",
    "\n",
    "eye = qeye(2)\n",
    "eyes = [eye]\n",
    "H = hadamard_transform()\n",
    "Hs = [H]\n",
    "for i in range(n+6):\n",
    "    eye = tensor(qeye(2),eye)\n",
    "    eyes += [eye]\n",
    "    H = tensor(hadamard_transform(),H)\n",
    "    Hs += [H]\n",
    "\n",
    "temp = W\n",
    "Wcs = [tensor(eyes[k-1],tensor(fock_dm(2,1),temp-eyes[3])+eyes[4])]\n",
    "for i in range(1,k):\n",
    "    temp = temp**2\n",
    "    Wcs += [tensor(eyes[k-i-1],tensor(fock_dm(2,1),tensor(eyes[i-1],temp)-eyes[i+3])+eyes[i+4])]\n",
    "Wcs+=[tensor(fock_dm(2,1),tensor(eyes[k-1],temp)-eyes[k+3])+eyes[k+4]]\n",
    "\n",
    "Mem = tensor(Aux, R)\n",
    "\n",
    "PD = tensor(Hs[k],eyes[3])\n",
    "for Wc in Wcs:\n",
    "    PD = Wc*PD\n",
    "PD = tensor(Hs[k],eyes[3])*PD\n",
    "D0aux = 2*nullaux*nullaux.dag()-eyes[k]\n",
    "ARO = PD.dag()*tensor(D0aux,eyes[3])*PD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.375, 0.0625, 0.0625]\n"
     ]
    }
   ],
   "source": [
    "print([p1/(1-lmbd),p2-p1*lmbd/(1-lmbd),p3/2,p3/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678  0.61237244  0.25        0.25      ]\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt([p1/(1-lmbd),p2-p1*lmbd/(1-lmbd),p3/2,p3/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\\begin{equation*}\\left(\\begin{array}{*{11}c}0.500\\\\0.750\\\\0.306\\\\0.306\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2], [1, 1]], shape = (4, 1), type = ket\n",
       "Qobj data =\n",
       "[[ 0.5       ]\n",
       " [ 0.75      ]\n",
       " [ 0.30618622]\n",
       " [ 0.30618622]]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2, 2, 2], [1, 1, 1, 1]], shape = (16, 1), type = ket\\begin{equation*}\\left(\\begin{array}{*{11}c}0.661\\\\0.0\\\\0.177\\\\0.177\\\\0.217\\\\\\vdots\\\\0.063\\\\0.088\\\\0.217\\\\0.063\\\\0.063\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2, 2, 2], [1, 1, 1, 1]], shape = (16, 1), type = ket\n",
       "Qobj data =\n",
       "[[ 0.66143783]\n",
       " [ 0.        ]\n",
       " [ 0.1767767 ]\n",
       " [ 0.1767767 ]\n",
       " [ 0.21650635]\n",
       " [ 0.53033009]\n",
       " [ 0.15309311]\n",
       " [ 0.15309311]\n",
       " [ 0.08838835]\n",
       " [ 0.21650635]\n",
       " [ 0.0625    ]\n",
       " [ 0.0625    ]\n",
       " [ 0.08838835]\n",
       " [ 0.21650635]\n",
       " [ 0.0625    ]\n",
       " [ 0.0625    ]]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Up*tensor(test,R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70710678118654757"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = 1 - lmbd\n",
    "sqrt(2*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7227342478134157"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.acos(lmbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(delta)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15542251,  0.23383926,  0.04591932,  0.04591932,  0.21252213,\n",
       "        0.08514513,  0.03208797,  0.03208797,  0.05469255,  0.02167367,\n",
       "        0.00108099,  0.00108099,  0.05469255,  0.02167367,  0.00108099,\n",
       "        0.00108099])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sqrt(p1/(1-lmbd))*tensor(basis(2,0),basis(2,0))+sqrt(p2-p1*lmbd/(1-lmbd))*tensor(basis(2,0),basis(2,1))+sqrt(p3/2)*tensor(basis(2,1),basis(2,0))+sqrt(p3/2)*tensor(basis(2,1),basis(2,1))\n",
    "out = np.array(measure(ARO*tensor(Aux,Up*tensor(test,R2)))[1])\n",
    "out = out.reshape(int(len(out)/16),16)\n",
    "out = np.sum(out, axis = 0)#.reshape(4,4)\n",
    "#np.sum(out,axis = 0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Quantum object: dims = [[2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1, 1]], shape = (256, 1), type = ket\\begin{equation*}\\left(\\begin{array}{*{11}c}0.200\\\\0.0\\\\0.015\\\\0.015\\\\-0.004\\\\\\vdots\\\\1.800\\times10^{-06}\\\\1.470\\times10^{-06}\\\\2.334\\times10^{-05}\\\\1.800\\times10^{-06}\\\\1.800\\times10^{-06}\\\\\\end{array}\\right)\\end{equation*}"
      ],
      "text/plain": [
       "Quantum object: dims = [[2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1, 1]], shape = (256, 1), type = ket\n",
       "Qobj data =\n",
       "[[ 0.19951773]\n",
       " [ 0.        ]\n",
       " [ 0.01536268]\n",
       " [ 0.01536268]\n",
       " [-0.00402404]\n",
       " [-0.06387965]\n",
       " [-0.00492842]\n",
       " [-0.00492842]\n",
       " [-0.00055227]\n",
       " [-0.008767  ]\n",
       " [-0.00067639]\n",
       " [-0.00067639]\n",
       " [-0.00055227]\n",
       " [-0.008767  ]\n",
       " [-0.00067639]\n",
       " [-0.00067639]\n",
       " [-0.00933697]\n",
       " [-0.00400251]\n",
       " [ 0.0606304 ]\n",
       " [ 0.0606304 ]\n",
       " [ 0.00402404]\n",
       " [ 0.00034177]\n",
       " [-0.00385776]\n",
       " [-0.00385776]\n",
       " [-0.06135055]\n",
       " [ 0.00386495]\n",
       " [-0.00000148]\n",
       " [-0.00000148]\n",
       " [-0.06135055]\n",
       " [ 0.00386495]\n",
       " [-0.00000148]\n",
       " [-0.00000148]\n",
       " [-0.01912958]\n",
       " [-0.00791135]\n",
       " [ 0.12421959]\n",
       " [ 0.12421959]\n",
       " [ 0.00795657]\n",
       " [ 0.0007178 ]\n",
       " [-0.00790013]\n",
       " [-0.00790013]\n",
       " [-0.12569488]\n",
       " [ 0.00791847]\n",
       " [-0.00000286]\n",
       " [-0.00000286]\n",
       " [-0.12569488]\n",
       " [ 0.00791847]\n",
       " [-0.00000286]\n",
       " [-0.00000286]\n",
       " [ 0.03848564]\n",
       " [ 0.        ]\n",
       " [ 0.00296336]\n",
       " [ 0.00296336]\n",
       " [-0.00009151]\n",
       " [-0.00145268]\n",
       " [-0.00011208]\n",
       " [-0.00011208]\n",
       " [ 0.00000465]\n",
       " [ 0.00007386]\n",
       " [ 0.0000057 ]\n",
       " [ 0.0000057 ]\n",
       " [ 0.00000465]\n",
       " [ 0.00007386]\n",
       " [ 0.0000057 ]\n",
       " [ 0.0000057 ]\n",
       " [-0.04251103]\n",
       " [-0.0148209 ]\n",
       " [ 0.27604904]\n",
       " [ 0.27604904]\n",
       " [ 0.01493204]\n",
       " [ 0.00176429]\n",
       " [-0.0175299 ]\n",
       " [-0.0175299 ]\n",
       " [-0.27932671]\n",
       " [ 0.01759675]\n",
       " [-0.00000534]\n",
       " [-0.00000534]\n",
       " [-0.27932671]\n",
       " [ 0.01759675]\n",
       " [-0.00000534]\n",
       " [-0.00000534]\n",
       " [ 0.08552547]\n",
       " [ 0.        ]\n",
       " [ 0.00658538]\n",
       " [ 0.00658538]\n",
       " [-0.00022471]\n",
       " [-0.00356719]\n",
       " [-0.00027521]\n",
       " [-0.00027521]\n",
       " [ 0.00000869]\n",
       " [ 0.00013798]\n",
       " [ 0.00001065]\n",
       " [ 0.00001065]\n",
       " [ 0.00000869]\n",
       " [ 0.00013798]\n",
       " [ 0.00001065]\n",
       " [ 0.00001065]\n",
       " [ 0.17522591]\n",
       " [ 0.        ]\n",
       " [ 0.01349223]\n",
       " [ 0.01349223]\n",
       " [-0.0004697 ]\n",
       " [-0.00745627]\n",
       " [-0.00057526]\n",
       " [-0.00057526]\n",
       " [ 0.00001709]\n",
       " [ 0.00027129]\n",
       " [ 0.00002093]\n",
       " [ 0.00002093]\n",
       " [ 0.00001709]\n",
       " [ 0.00027129]\n",
       " [ 0.00002093]\n",
       " [ 0.00002093]\n",
       " [ 0.00207517]\n",
       " [-0.00047977]\n",
       " [-0.01347528]\n",
       " [-0.01347528]\n",
       " [ 0.0004697 ]\n",
       " [-0.00015986]\n",
       " [ 0.00084425]\n",
       " [ 0.00084425]\n",
       " [ 0.01363492]\n",
       " [-0.00085889]\n",
       " [-0.00000018]\n",
       " [-0.00000018]\n",
       " [ 0.01363492]\n",
       " [-0.00085889]\n",
       " [-0.00000018]\n",
       " [-0.00000018]\n",
       " [-0.04251103]\n",
       " [-0.0148209 ]\n",
       " [ 0.27604904]\n",
       " [ 0.27604904]\n",
       " [ 0.01493204]\n",
       " [ 0.00176429]\n",
       " [-0.0175299 ]\n",
       " [-0.0175299 ]\n",
       " [-0.27932671]\n",
       " [ 0.01759675]\n",
       " [-0.00000534]\n",
       " [-0.00000534]\n",
       " [-0.27932671]\n",
       " [ 0.01759675]\n",
       " [-0.00000534]\n",
       " [-0.00000534]\n",
       " [ 0.08552547]\n",
       " [ 0.        ]\n",
       " [ 0.00658538]\n",
       " [ 0.00658538]\n",
       " [-0.00022471]\n",
       " [-0.00356719]\n",
       " [-0.00027521]\n",
       " [-0.00027521]\n",
       " [ 0.00000869]\n",
       " [ 0.00013798]\n",
       " [ 0.00001065]\n",
       " [ 0.00001065]\n",
       " [ 0.00000869]\n",
       " [ 0.00013798]\n",
       " [ 0.00001065]\n",
       " [ 0.00001065]\n",
       " [ 0.17522591]\n",
       " [ 0.        ]\n",
       " [ 0.01349223]\n",
       " [ 0.01349223]\n",
       " [-0.0004697 ]\n",
       " [-0.00745627]\n",
       " [-0.00057526]\n",
       " [-0.00057526]\n",
       " [ 0.00001709]\n",
       " [ 0.00027129]\n",
       " [ 0.00002093]\n",
       " [ 0.00002093]\n",
       " [ 0.00001709]\n",
       " [ 0.00027129]\n",
       " [ 0.00002093]\n",
       " [ 0.00002093]\n",
       " [ 0.00207517]\n",
       " [-0.00047977]\n",
       " [-0.01347528]\n",
       " [-0.01347528]\n",
       " [ 0.0004697 ]\n",
       " [-0.00015986]\n",
       " [ 0.00084425]\n",
       " [ 0.00084425]\n",
       " [ 0.01363492]\n",
       " [-0.00085889]\n",
       " [-0.00000018]\n",
       " [-0.00000018]\n",
       " [ 0.01363492]\n",
       " [-0.00085889]\n",
       " [-0.00000018]\n",
       " [-0.00000018]\n",
       " [ 0.38941174]\n",
       " [ 0.        ]\n",
       " [ 0.02998433]\n",
       " [ 0.02998433]\n",
       " [-0.00113274]\n",
       " [-0.01798162]\n",
       " [-0.00138731]\n",
       " [-0.00138731]\n",
       " [ 0.00003112]\n",
       " [ 0.00049403]\n",
       " [ 0.00003812]\n",
       " [ 0.00003812]\n",
       " [ 0.00003112]\n",
       " [ 0.00049403]\n",
       " [ 0.00003812]\n",
       " [ 0.00003812]\n",
       " [ 0.00461279]\n",
       " [-0.00115546]\n",
       " [-0.02995356]\n",
       " [-0.02995356]\n",
       " [ 0.00113274]\n",
       " [-0.0003608 ]\n",
       " [ 0.0018758 ]\n",
       " [ 0.0018758 ]\n",
       " [ 0.03030839]\n",
       " [-0.00190918]\n",
       " [-0.00000043]\n",
       " [-0.00000043]\n",
       " [ 0.03030839]\n",
       " [-0.00190918]\n",
       " [-0.00000043]\n",
       " [-0.00000043]\n",
       " [ 0.00945129]\n",
       " [-0.00240625]\n",
       " [-0.06137274]\n",
       " [-0.06137274]\n",
       " [ 0.00235953]\n",
       " [-0.00074163]\n",
       " [ 0.00384301]\n",
       " [ 0.00384301]\n",
       " [ 0.06209975]\n",
       " [-0.00391178]\n",
       " [-0.00000089]\n",
       " [-0.00000089]\n",
       " [ 0.06209975]\n",
       " [-0.00391178]\n",
       " [-0.00000089]\n",
       " [-0.00000089]\n",
       " [-0.01901476]\n",
       " [ 0.        ]\n",
       " [-0.00146412]\n",
       " [-0.00146412]\n",
       " [ 0.00009406]\n",
       " [ 0.0014932 ]\n",
       " [ 0.0001152 ]\n",
       " [ 0.0001152 ]\n",
       " [ 0.00000147]\n",
       " [ 0.00002334]\n",
       " [ 0.0000018 ]\n",
       " [ 0.0000018 ]\n",
       " [ 0.00000147]\n",
       " [ 0.00002334]\n",
       " [ 0.0000018 ]\n",
       " [ 0.0000018 ]]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null = tensor(basis(2,0),basis(2,0))\n",
    "refAct = eyes[k+4]-tensor(eyes[k],tensor(2*null*null.dag(),eyes[1]))\n",
    "Memb = tensor(Aux, Up*R)\n",
    "ARO*refAct*Memb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57815862,  0.10606541,  0.15788799,  0.15788799])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mes = np.array(measure(ARO*refAct*Memb)[1])\n",
    "mes = mes.reshape(int(len(mes)/16),16)\n",
    "mes = np.sum(mes, axis = 0).reshape(4,4)\n",
    "np.sum(mes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
